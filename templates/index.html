<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whiskers Chat</title>
    <link rel="stylesheet" href="/static/styles.css">
</head>
<body>
    <div class="container">
        <h1>Chat with Whiskers! üê±</h1>
        <div class="cat-emoji">üê±</div>
        <div id="chatbox" class="chatbox"></div>
        <div id="loading" class="loading" style="display: none;">
            <div class="typing-indicator">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        <div id="audio-permission" style="display: none;" class="audio-permission-overlay">
            <div class="audio-permission-content">
                <h2>Enable Audio for Whiskers</h2>
                <p>Whiskers needs permission to speak on your device!</p>
                <button id="enable-audio" class="audio-button">Enable Whiskers Voice</button>
                <button id="test-audio" class="audio-button">Test Audio</button>
                <button id="dismiss-audio-warning" class="audio-button secondary">Continue without Audio</button>
            </div>
        </div>
        <div class="input-container">
            <div class="input-wrapper">
                <textarea id="message" placeholder="Type your message here..." maxlength="200" readonly></textarea>
                <button id="mic" class="mic-button" title="Click to start/stop listening">
                    üé§
                </button>
            </div>
            <div class="buttons">
                <button id="stop" disabled>Stop</button>
                <button id="clear">Clear Chat</button>
            </div>
        </div>
    </div>

    <script>
    const chatbox = document.getElementById('chatbox');
    const messageInput = document.getElementById('message');
    const stopBtn = document.getElementById('stop');
    const clearBtn = document.getElementById('clear');
    const micBtn = document.getElementById('mic');
    const loading = document.getElementById('loading');
    const audioPermissionMessage = document.getElementById('audio-permission');

    // Audio initialization state
    let audioInitialized = false;
    
    // Detect iOS
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
    const isAndroid = /Android/i.test(navigator.userAgent);

    // Initialize speech synthesis
    const synth = window.speechSynthesis;
    let currentUtterance = null;
    let isSpeaking = false;
    let isConversationActive = false;
    let voicesReady = false;

    function loadVoices() {
        if (synth.getVoices().length > 0) {
            voicesReady = true;
            speechSynthesis.removeEventListener('voiceschanged', loadVoices);
        }
    }

    // Attempt to load voices immediately and listen for changes
    loadVoices();
    if (!voicesReady) {
        speechSynthesis.addEventListener('voiceschanged', loadVoices);
    }

    // Check if browser supports speech recognition
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition = null;
    let isListening = false;
    let finalTranscript = '';
    let interimTranscript = '';

    // Show audio permission dialog for iOS devices
    if (isIOS) {
        audioPermissionMessage.style.display = 'block';
        
        // Handle dismiss button
        document.getElementById('dismiss-audio-warning').addEventListener('click', () => {
            audioPermissionMessage.style.display = 'none';
        });
        
        // Handle enable audio button
        document.getElementById('enable-audio').addEventListener('click', () => {
            initializeAudio();
            
            // Show feedback to the user
            const enableButton = document.getElementById('enable-audio');
            enableButton.textContent = "Audio Enabled!";
            enableButton.style.backgroundColor = "#4CAF50";
            
            // Hide the overlay after a short delay
            setTimeout(() => {
                audioPermissionMessage.style.display = 'none';
            }, 1500);
        });
        
        // Handle test audio button
        document.getElementById('test-audio').addEventListener('click', () => {
            try {
                // Play a test sound
                const testAudio = new Audio("https://cdn.freesound.org/previews/242/242758_4484625-lq.mp3");
                testAudio.volume = 1.0;
                
                const testButton = document.getElementById('test-audio');
                testButton.textContent = "Playing test...";
                
                testAudio.play().then(() => {
                    testButton.textContent = "Audio Works! ‚úì";
                    testButton.style.backgroundColor = "#4CAF50";
                }).catch(error => {
                    console.error("Test audio error:", error);
                    testButton.textContent = "Audio Failed! Try again";
                    testButton.style.backgroundColor = "#F44336";
                });
            } catch (error) {
                console.error("Error setting up test audio:", error);
            }
        });
    }

    // Function to initialize audio for iOS
    function initializeAudio() {
        if (audioInitialized) return;
        
        console.log("Initializing audio for speech synthesis...");
        
        // Create a short silent sound and play it to initialize audio context
        const AudioContext = window.AudioContext || window.webkitAudioContext;
        if (AudioContext) {
            const audioContext = new AudioContext();
            const gainNode = audioContext.createGain();
            gainNode.gain.value = 0; // Silent
            gainNode.connect(audioContext.destination);
            
            // Create and play a short sound
            const oscillator = audioContext.createOscillator();
            oscillator.connect(gainNode);
            oscillator.start();
            oscillator.stop(0.001);
        }
        
        // Play a silent audio to unlock audio playback on iOS
        const silentAudio = new Audio("data:audio/mp3;base64,//uQxAAAAAAAAAAAAAAAAAAAAAAAWGluZwAAAA8AAAACAAACcQCAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgAAAAA=");
        silentAudio.play().catch(e => console.log("Silent audio play error:", e));
        
        // Try to initialize speech synthesis
        if ('speechSynthesis' in window) {
            // Create a short utterance and speak it silently
            const speech = new SpeechSynthesisUtterance('');
            speech.volume = 0;
            window.speechSynthesis.speak(speech);
        }
        
        audioInitialized = true;
        console.log("Audio initialization complete!");
        
        return true;
    }

    // Initialize audio on first user interaction for all devices
    document.body.addEventListener('click', () => {
        if (!audioInitialized) {
            initializeAudio();
        }
    }, { once: true });

    function updateStopButton() {
        stopBtn.disabled = !isConversationActive;
    }

    if (SpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';

        recognition.onstart = () => {
            micBtn.classList.add('listening');
            isListening = true;
            isConversationActive = true;
            updateStopButton();
            messageInput.placeholder = "Listening...";
        };

        recognition.onresult = (event) => {
            // Don't process results while Whiskers is speaking
            if (isSpeaking) return;

            interimTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const transcript = event.results[i][0].transcript;
                if (event.results[i].isFinal) {
                    finalTranscript = transcript;
                    messageInput.value = finalTranscript;
                    // Automatically send the message when final transcript is received
                    sendMessage(finalTranscript);
                } else {
                    interimTranscript += transcript;
                    messageInput.value = interimTranscript;
                }
            }
        };

        recognition.onend = () => {
            if (isListening && !isSpeaking) {
                // Restart recognition if we're still supposed to be listening and not speaking
                try {
                    recognition.start();
                } catch (error) {
                    console.error('Error restarting speech recognition:', error);
                }
            } else {
                micBtn.classList.remove('listening');
                messageInput.placeholder = "Type your message here...";
            }
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            if (event.error === 'no-speech') {
                // Ignore no-speech errors as they're common
                return;
            }
            micBtn.classList.remove('listening');
            isListening = false;
            isConversationActive = false;
            updateStopButton();
            addMessage('Sorry, I had trouble understanding you. Please try again.');
        };
    } else {
        micBtn.style.display = 'none';
        console.warn('Speech recognition not supported in this browser');
    }

    function speak(text) {
        // First make sure audio is initialized (especially important for iOS)
        if (!audioInitialized && (isIOS || isAndroid)) {
            initializeAudio();
        }

        // Filter out emojis and symbols for speech
        const cleanText = text.replace(/[\u{1F300}-\u{1F9FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}\u{1F000}-\u{1F02F}\u{1F0A0}-\u{1F0FF}\u{1F100}-\u{1F64F}\u{1F680}-\u{1F6FF}\u{1F900}-\u{1F9FF}\u{1F1E0}-\u{1F1FF}\u{1F200}-\u{1F2FF}\u{1F600}-\u{1F64F}\u{1F680}-\u{1F6FF}\u{1F700}-\u{1F77F}\u{1F780}-\u{1F7FF}\u{1F800}-\u{1F8FF}\u{1F900}-\u{1F9FF}\u{1FA00}-\u{1FA6F}\u{1FA70}-\u{1FAFF}\u{1FAB0}-\u{1FABF}\u{1FAC0}-\u{1FAFF}\u{1FAD0}-\u{1FAFF}\u{1FAE0}-\u{1FAFF}\u{1FAF0}-\u{1FAFF}\u{1FB00}-\u{1FBFF}\u{1FC00}-\u{1FCFF}\u{1FD00}-\u{1FDFF}\u{1FE00}-\u{1FEFF}\u{1FF00}-\u{1FFFF}\u{2000}-\u{206F}\u{2070}-\u{209F}\u{20A0}-\u{20CF}\u{20D0}-\u{20FF}\u{2100}-\u{214F}\u{2150}-\u{218F}\u{2190}-\u{21FF}\u{2200}-\u{22FF}\u{2300}-\u{23FF}\u{2400}-\u{243F}\u{2440}-\u{245F}\u{2460}-\u{24FF}\u{2500}-\u{257F}\u{2580}-\u{259F}\u{25A0}-\u{25FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}\u{2800}-\u{28FF}\u{2900}-\u{297F}\u{2980}-\u{29FF}\u{2A00}-\u{2AFF}\u{2B00}-\u{2BFF}\u{2C00}-\u{2C5F}\u{2C60}-\u{2C7F}\u{2C80}-\u{2CFF}\u{2D00}-\u{2D2F}\u{2D30}-\u{2D7F}\u{2D80}-\u{2DDF}\u{2DE0}-\u{2DFF}\u{2E00}-\u{2E7F}\u{2E80}-\u{2EFF}\u{2F00}-\u{2FDF}\u{2FF0}-\u{2FFF}\u{3000}-\u{303F}\u{3040}-\u{309F}\u{30A0}-\u{30FF}\u{3100}-\u{312F}\u{3130}-\u{318F}\u{3190}-\u{319F}\u{31A0}-\u{31BF}\u{31C0}-\u{31EF}\u{31F0}-\u{31FF}\u{3200}-\u{32FF}\u{3300}-\u{33FF}\u{3400}-\u{4DBF}\u{4DC0}-\u{4DFF}\u{4E00}-\u{9FFF}\u{A000}-\u{A48F}\u{A490}-\u{A4CF}\u{A4D0}-\u{A4FF}\u{A500}-\u{A63F}\u{A640}-\u{A69F}\u{A6A0}-\u{A6FF}\u{A700}-\u{A71F}\u{A720}-\u{A7FF}\u{A800}-\u{A82F}\u{A830}-\u{A83F}\u{A840}-\u{A87F}\u{A880}-\u{A8DF}\u{A8E0}-\u{A8FF}\u{A900}-\u{A92F}\u{A930}-\u{A95F}\u{A960}-\u{A97F}\u{A980}-\u{A9DF}\u{A9E0}-\u{A9FF}\u{AA00}-\u{AA5F}\u{AA60}-\u{AA7F}\u{AA80}-\u{AADF}\u{AAE0}-\u{AAFF}\u{AB00}-\u{AB2F}\u{AB30}-\u{AB6F}\u{AB70}-\u{ABBF}\u{ABC0}-\u{ABFF}\u{AC00}-\u{D7AF}\u{D7B0}-\u{D7FF}\u{D800}-\u{DB7F}\u{DB80}-\u{DBFF}\u{DC00}-\u{DFFF}\u{E000}-\u{F8FF}\u{F900}-\u{FAFF}\u{FB00}-\u{FB4F}\u{FB50}-\u{FDFF}\u{FE00}-\u{FE0F}\u{FE10}-\u{FE1F}\u{FE20}-\u{FE2F}\u{FE30}-\u{FE4F}\u{FE50}-\u{FE6F}\u{FE70}-\u{FEFF}\u{FF00}-\u{FFEF}\u{FFF0}-\u{FFFF}]/gu, '');

        if (!voicesReady && synth.getVoices().length === 0) {
            speechSynthesis.addEventListener("voiceschanged", () => speak(text), { once: true });
            synth.getVoices();
            return;
        }
        // Cancel any ongoing speech
        if (currentUtterance) {
            synth.cancel();
        }

        const utterance = new SpeechSynthesisUtterance(cleanText);
        utterance.lang = 'en-US';

        // Configure voice settings for a more natural sound
        utterance.rate = 0.95;
        utterance.pitch = 1.0;
        utterance.volume = 1.0;

        // Special handling for iOS voices
        let voiceList = synth.getVoices();
        
        // For iOS devices, wait a moment before trying to get voices if the list is empty
        if (isIOS && (!voiceList || voiceList.length === 0)) {
            console.log("No voices available yet, waiting for voices to load...");
            setTimeout(() => {
                voiceList = synth.getVoices();
                selectVoiceAndSpeak();
            }, 1000);
        } else {
            selectVoiceAndSpeak();
        }

        function selectVoiceAndSpeak() {
            // Try to select a natural-sounding voice if available
            const voices = synth.getVoices();
            console.log("Available voices:", voices.length);
            
            let selectedVoice = null;
            
            // First try iOS-specific voices
            if (isIOS) {
                selectedVoice = voices.find(voice =>
                    voice.name.includes('Samantha') ||
                    voice.name.includes('Karen') ||
                    voice.name.includes('Moira') ||
                    voice.name.includes('Tessa')
                );
            }
            
            // If no iOS-specific voice found, try common voices
            if (!selectedVoice) {
                selectedVoice = voices.find(voice =>
                    voice.name.includes('Google US English') ||
                    voice.name.includes('Google UK English Female') ||
                    voice.name.includes('Microsoft Aria') ||
                    voice.name.includes('Microsoft Jenny') ||
                    voice.name.includes('Samantha')
                );
            }
            
            // Default to any female voice as fallback
            if (!selectedVoice) {
                selectedVoice = voices.find(voice =>
                    voice.name.toLowerCase().includes('female') ||
                    voice.name.includes('Samantha')
                );
            }
            
            if (selectedVoice) {
                utterance.voice = selectedVoice;
                console.log("Selected voice:", selectedVoice.name);
            } else if (voices.length > 0) {
                // Just use the first available voice if nothing else works
                utterance.voice = voices[0];
                console.log("Using default voice:", voices[0].name);
            }

            // Pause recognition while speaking
            if (isListening) {
                recognition.stop();
            }
            isSpeaking = true;
            isConversationActive = true;
            updateStopButton();

            utterance.onstart = () => {
                micBtn.classList.add('speaking');
            };

            utterance.onend = () => {
                isSpeaking = false;
                micBtn.classList.remove('speaking');
                // Resume recognition if we're still supposed to be listening
                if (isListening) {
                    try {
                        recognition.start();
                    } catch (error) {
                        console.error('Error restarting speech recognition:', error);
                    }
                } else {
                    isConversationActive = false;
                    updateStopButton();
                }
            };

            // Handle iOS-specific issues with onend not firing
            if (isIOS) {
                // Set a timeout based on text length to handle cases where onend doesn't fire
                const textLength = cleanText.length;
                const timeEstimate = Math.max(2000, textLength * 90); // ~90ms per character, minimum 2 seconds
                
                setTimeout(() => {
                    if (isSpeaking) {
                        console.log("iOS speech timeout - ending manually");
                        isSpeaking = false;
                        micBtn.classList.remove('speaking');
                        
                        // Resume recognition if needed
                        if (isListening) {
                            try {
                                recognition.start();
                            } catch (error) {
                                console.error('Error restarting speech recognition:', error);
                            }
                        } else {
                            isConversationActive = false;
                            updateStopButton();
                        }
                    }
                }, timeEstimate);
            }

            currentUtterance = utterance;
            try {
                synth.speak(utterance);
                console.log("Speaking now:", cleanText.substring(0, 50) + "...");
            } catch (error) {
                console.error("Speech synthesis error:", error);
                isSpeaking = false;
                micBtn.classList.remove('speaking');
            }
        }
    }

    function addMessage(text, isUser = false) {
        const div = document.createElement('div');
        div.className = isUser ? 'user' : 'whiskers';
        div.textContent = `${isUser ? 'You' : 'Whiskers'}: ${text}`;
        chatbox.appendChild(div);
        chatbox.scrollTop = chatbox.scrollHeight;

        // Speak out Whiskers' responses
        if (!isUser) {
            speak(text);
        }
    }

    function setLoading(isLoading) {
        loading.style.display = isLoading ? 'block' : 'none';
        isConversationActive = isLoading;
        updateStopButton();
    }

    async function sendMessage(text) {
        if (!text.trim()) return;
        
        addMessage(text, true);
        setLoading(true);
        messageInput.value = '';
        
        try {
            const response = await fetch('/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({message: text})
            });
            const data = await response.json();
            addMessage(data.reply);
        } catch (error) {
            addMessage('Sorry, something went wrong. Please try again.');
        } finally {
            setLoading(false);
        }
    }

    micBtn.addEventListener('click', () => {
        if (!recognition) return;
        
        if (!isListening) {
            try {
                // Ensure audio is initialized before starting speech recognition
                if (!audioInitialized) {
                    initializeAudio();
                }
                
                finalTranscript = '';
                interimTranscript = '';
                messageInput.value = '';
                recognition.start();
            } catch (error) {
                console.error('Error starting speech recognition:', error);
            }
        } else {
            isListening = false;
            isConversationActive = false;
            updateStopButton();
            recognition.stop();
        }
    });

    stopBtn.addEventListener('click', () => {
        // Stop speech recognition
        if (isListening) {
            isListening = false;
            recognition.stop();
        }
        
        // Stop any ongoing speech
        if (currentUtterance) {
            synth.cancel();
        }
        
        // Reset states
        isSpeaking = false;
        isConversationActive = false;
        setLoading(false);
        micBtn.classList.remove('listening', 'speaking');
        messageInput.value = '';
        messageInput.placeholder = "Type your message here...";
    });

    clearBtn.addEventListener('click', () => {
        chatbox.innerHTML = '';
        // Stop any ongoing speech
        if (currentUtterance) {
            synth.cancel();
        }
        // Reset states
        isSpeaking = false;
        isConversationActive = false;
        updateStopButton();
    });

    // Add keyboard shortcut for toggling speech recognition
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape') {
            if (isListening) {
                isListening = false;
                recognition.stop();
            }
            // Stop any ongoing speech
            if (currentUtterance) {
                synth.cancel();
            }
            // Reset states
            isSpeaking = false;
            isConversationActive = false;
            updateStopButton();
        }
    });

    // Initialize voices when they become available
    if (speechSynthesis.onvoiceschanged !== undefined) {
        speechSynthesis.onvoiceschanged = () => {
            // Voices are now available
            console.log('Voices loaded:', speechSynthesis.getVoices().length);
        };
    }
    </script>
</body>
</html>
